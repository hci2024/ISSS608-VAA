[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Visual Analytics and Application Learning Journey!",
    "section": "",
    "text": "Greetings!\nI am delighted to welcome you to this dedicated space where I share my insights and experiences throughout my Visual Analytics Course (ISSS608) under the guidance of Professor Kam Tin Seong. This journey is a part of my Master of IT in Business (MITB) at Singapore Management University.\n\n\nWhat to Expect\nThis website serves as a comprehensive repository of the visual analytics journey I undertook during the course. You’ll find a collection of exercises, projects, and reflections that not only showcase my progress but also reflect the skills and knowledge gained throughout this learning adventure.\n\n\nNavigation\nTo explore my learning journey, simply navigate through the tabs on the top. Each tab corresponds to a different aspect of the course, providing you with a structured and organized way to follow my progression.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercises\nIn-class Exercises\nTake-home Exercises\n\n\n\n\n\nLatest Posts\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nModelling, Visualising and Analysing Network Data with R\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Take-home Exercise 4: Exploratory Data Analysis for Visual Analytics Shiny Application",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggiraph, ggstatsplot, patchwork, ggthemes, sf, terra, gstat, automap, tmap, viridis)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#installing-and-launching-the-required-r-packages",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#installing-and-launching-the-required-r-packages",
    "title": "Take-home Exercise 4: Exploratory Data Analysis for Visual Analytics Shiny Application",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggiraph, ggstatsplot, patchwork, ggthemes, sf, terra, gstat, automap, tmap, viridis)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#importing-the-data",
    "title": "Take-home Exercise 4: Exploratory Data Analysis for Visual Analytics Shiny Application",
    "section": "2. Importing the data",
    "text": "2. Importing the data\nThe datasets to be used can be obtained from Meteorological Service Singapore.\n\nclimate_data &lt;- read_csv(\"data/clean_climate_data.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#understanding-the-weather-data-over-time",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#understanding-the-weather-data-over-time",
    "title": "Take-home Exercise 4: Exploratory Data Analysis for Visual Analytics Shiny Application",
    "section": "3. Understanding the weather data over time",
    "text": "3. Understanding the weather data over time\nThe user will be able to select weather station and measurement variable (mean_temp, daily_rainfall, mean_wind).\nInputs for prototyping:\n\ninput_station &lt;- \"Changi\"\ninput_msmt &lt;- \"mean_temp\"\n\nNext, the code chunk below will filter the selected weather station and measurement variable, to prepare the input data.\n\ninput_data &lt;- climate_data %&gt;%\n  select('Station','Year','Month','Day',input_msmt)%&gt;%\n  filter(Station == input_station,\n         Year %in% c(2018, 2019, 2021))\n\n\n3.1 Distribution of Weather Data Over the Years\n\nggplot(input_data,\n             aes(x = factor(Year), y = !!rlang::sym(input_msmt))) +\n  geom_boxplot(fill = \"grey\") +\n  coord_cartesian(ylim = c(23.5, 29.5)) +\n    labs(title = paste0(input_msmt, \" Distribution at \", input_station), x = \"Year\") +\n  theme_minimal() +\ntheme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1),\n  axis.title.x = element_blank(),\n  axis.title.y = element_blank())\n\n\n\n\n\nggbetweenstats(\n  data = input_data,\n  x = Year, \n  y = !!rlang::sym(input_msmt),\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n3.2 Cycle Plot of Weather Data Over the Years\nAggregating the input measurement variable by Year and Month:\n\ninput_data_month &lt;- aggregate(as.formula(paste(input_msmt, \"~ Year + Month\")), \n                              data = climate_data, \n                              FUN = mean)\n\nComputing the monthly average of the input measurement variable over the years:\n\nhline.data &lt;- input_data_month %&gt;% \n  group_by(Month) %&gt;%\n  summarise(avgvalue = mean(!!rlang::sym(input_msmt)))\n\nPlotting the cycle plot:\n\nggplot() + \n  geom_line(data=input_data_month,\n            aes(x=Year, \n                y=!!rlang::sym(input_msmt), \n                group=Month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~Month) +\n  labs(axis.text.x = element_blank(),\n       title = paste0(\"Monthly \", input_msmt, \" Over the Years at \", input_station)) +\n  xlab(\"\") +\n  ylab(input_msmt) +\n  theme_tufte(base_family = \"Helvetica\")+\n  theme(axis.text.x = element_text(angle = 60, vjust = 0.5, hjust=0.5))\n\n\n\n\n\n\n3.3 UI Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#geographical-analysis-of-weather-data-by-region",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#geographical-analysis-of-weather-data-by-region",
    "title": "Take-home Exercise 4: Exploratory Data Analysis for Visual Analytics Shiny Application",
    "section": "4. Geographical analysis of weather data by region",
    "text": "4. Geographical analysis of weather data by region\nImporting the station data:\n\nstations &lt;- read_csv(\"data/aspatial/RainfallStation.csv\")\n\nThe user will be able to select the year, measurement variable (mean_temp, daily_rainfall, mean_wind), and the way to aggregate.\nInputs for prototyping:\n\ninput_year &lt;- 2023\ninput_msmt &lt;- \"daily_rainfall\"\ninput_agg &lt;- \"sum\"\n\nPreparing the input data:\n\ninput_data &lt;- climate_data %&gt;%\n  select('Station','Year','Month','Day',input_msmt)%&gt;%\n  filter(Year == input_year)\n\nrfdata &lt;- input_data%&gt;%\n  select(c(1,5))%&gt;%\n  group_by(Station)%&gt;%\n  summarise(year_sum = sum(!!rlang::sym(input_msmt)))%&gt;%\n  mutate(\n    year_sum = ifelse(is.na(year_sum), 0, year_sum),\n  )%&gt;%\n  ungroup()\n\nConverting aspatial data into geospatial data:\n\nrfdata &lt;- rfdata %&gt;%\n  left_join(stations)\n\nrfdata_sf&lt;- st_as_sf(rfdata,\n                     coords = c(\"Longitude\", \"Latitude\"),\n                     crs = 4326)%&gt;%\n  st_transform(crs = 3414)\n\nImporting planning subzone boundary data:\n\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\")%&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\hci2024\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n4.1 Quantitative Dot Map of Rainfall Distribution by Stations\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\ntm_shape(mpsz2019)+\n  tm_borders()+\ntm_shape(rfdata_sf)+\n  tm_dots(col = 'year_sum')\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n4.2 Spatial Interpolation\n\ngrid &lt;- terra::rast(mpsz2019, \n                    nrows = 690, \n                    ncols = 1075)\n\nxy &lt;- terra::xyFromCell(grid, \n                        1:ncell(grid))\n\ncoop &lt;- st_as_sf(as.data.frame(xy), \n                 coords = c(\"x\", \"y\"),\n                 crs = st_crs(mpsz2019))\ncoop &lt;- st_filter(coop, mpsz2019)\n\nres &lt;- gstat(formula = year_sum ~ 1, \n             locations = rfdata_sf, \n             nmax = 5,\n             set = list(idp = 0))\n\nresp &lt;- predict(res, coop)\n\n[inverse distance weighted interpolation]\n\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\", \n                         fun = \"mean\")\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\")\n\n\n\n\n\n\n4.3 UI Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#correlation-analysis",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#correlation-analysis",
    "title": "Take-home Exercise 4: Exploratory Data Analysis for Visual Analytics Shiny Application",
    "section": "5. Correlation analysis",
    "text": "5. Correlation analysis\nThe user will be able to select the variables for coorelatioin analysis.\nInputs for prototyping:\n\ninput1 &lt;- \"mean_temp\"\ninput2 &lt;- \"daily_rainfall\"\ninput3 &lt;- \"mean_wind\"\n\nPreparing the input data:\n\ncor_data &lt;- climate_data %&gt;%\n  select('Year','Month','Day',input1, input2, input3)\n\nThe result:\n\nggstatsplot::ggcorrmat(\n  data = cor_data, \n  cor.vars = 4:6)\n\n\n\n\n\nUI Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "",
    "text": "The objective of this exercise is to create an analytics-driven data visualization to validate the claims that daily mean temperatures are projected to increase by 1.4 to 4.6. To achieve this, we will employ techniques of visual interactivity and uncertainty visualization.\nThe historical daily temperature datasets were downloaded from Meteorological Service Singapore website, consisting of daily mean temperatures recorded for January in the year 1983, 1993, 2003, 2013, and 2023 at the Changi weather station."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "",
    "text": "The objective of this exercise is to create an analytics-driven data visualization to validate the claims that daily mean temperatures are projected to increase by 1.4 to 4.6. To achieve this, we will employ techniques of visual interactivity and uncertainty visualization.\nThe historical daily temperature datasets were downloaded from Meteorological Service Singapore website, consisting of daily mean temperatures recorded for January in the year 1983, 1993, 2003, 2013, and 2023 at the Changi weather station."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-started",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required R packages\nIn this exercise, we use p_load() of pacman package to load required R packages. The packages that will be used are:\n\ntidyverse a family of R packages for data science process,\nggstatsplot package to create visual graphics with rich statistical information,\nggiraph for making ‘ggplot’ graphics interactive,\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\n\nCode\npacman::p_load(tidyverse, ggiraph, ggstatsplot, patchwork)\n\n\n\n\n2.2 Importing the data\n\nImportPreview\n\n\nThe downloaded datasets consist of five separate CSV files. The code chunk below imports all the five files into R environment by using read_csv() function of readr package.\n\ndata_1983 &lt;- read_csv(\"data/DAILYDATA_S24_198301.csv\",locale=locale(encoding=\"latin1\"))\ndata_1993 &lt;- read_csv(\"data/DAILYDATA_S24_199301.csv\",locale=locale(encoding=\"latin1\"))\ndata_2003 &lt;- read_csv(\"data/DAILYDATA_S24_200301.csv\",locale=locale(encoding=\"latin1\"))\ndata_2013 &lt;- read_csv(\"data/DAILYDATA_S24_201301.csv\",locale=locale(encoding=\"latin1\"))\ndata_2023 &lt;- read_csv(\"data/DAILYDATA_S24_202301.csv\",locale=locale(encoding = \"UTF-8\"))\n\nNext, we will merge the data and save the resulting object to an RDS file, which will then be loaded into the working environment.\n\ntemp_data &lt;- bind_rows(data_1983, data_1993, data_2003, data_2013, data_2023)\nwrite_rds(temp_data,\"data/temp_data.rds\")\n\n\ntemp_data &lt;- read_rds(\"data/temp_data.rds\")\n\n\n\n\n\nCode\nhead(temp_data)\n\n\n# A tibble: 6 × 16\n  Station  Year Month   Day `Daily Rainfall Total (mm)` Highest 30 Min Rainfal…¹\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;                       &lt;dbl&gt; &lt;chr&gt;                   \n1 Changi   1983     1     1                         0.3 \"\\u0097\"                \n2 Changi   1983     1     2                         0.4 \"\\u0097\"                \n3 Changi   1983     1     3                         2.9 \"\\u0097\"                \n4 Changi   1983     1     4                         0   \"\\u0097\"                \n5 Changi   1983     1     5                         0   \"\\u0097\"                \n6 Changi   1983     1     6                         0   \"\\u0097\"                \n# ℹ abbreviated name: ¹​`Highest 30 Min Rainfall (mm)`\n# ℹ 10 more variables: `Highest 60 Min Rainfall (mm)` &lt;chr&gt;,\n#   `Highest 120 Min Rainfall (mm)` &lt;chr&gt;, `Mean Temperature (°C)` &lt;dbl&gt;,\n#   `Maximum Temperature (°C)` &lt;dbl&gt;, `Minimum Temperature (°C)` &lt;dbl&gt;,\n#   `Mean Wind Speed (km/h)` &lt;dbl&gt;, `Max Wind Speed (km/h)` &lt;dbl&gt;,\n#   `Highest 30 min Rainfall (mm)` &lt;dbl&gt;, `Highest 60 min Rainfall (mm)` &lt;dbl&gt;,\n#   `Highest 120 min Rainfall (mm)` &lt;dbl&gt;\n\n\n\n\n\n\n\n2.3 Variables Selection\nWe will select our variables of interest from 13 variables and narrow them down to 6 variables. They are: Year, Month, Day, Mean Temperature (°C), Maximum Temperature (°C), Minimum Temperature (°C). Subsequently, we will simplify the variable names for convenience.\n\nCodePreview\n\n\n\n# select variables\nsubset &lt;- temp_data %&gt;%\n  select('Year','Month','Day','Mean Temperature (°C)','Maximum Temperature (°C)',\n         'Minimum Temperature (°C)')\n\n# rename\nsubset &lt;- subset %&gt;%\n  rename('Mean_temp'='Mean Temperature (°C)',\n         'Max_temp'='Maximum Temperature (°C)',\n         'Min_temp'='Minimum Temperature (°C)')\n\n\n\n\n\nCode\nhead(subset)\n\n\n# A tibble: 6 × 6\n   Year Month   Day Mean_temp Max_temp Min_temp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  1983     1     1      26.5     28.7     25.1\n2  1983     1     2      26.8     30.6     24.8\n3  1983     1     3      27       31.3     24.5\n4  1983     1     4      27.3     30.8     25  \n5  1983     1     5      27.1     31.8     23.7\n6  1983     1     6      27.2     32.1     23.7"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualisation",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "3. Data Visualisation",
    "text": "3. Data Visualisation\n\n3.1 Visualizing the Uncertainty of Historical Temperature\nA boxplot will be generated to visualize the distribution of historical daily mean temperature data for January of each year. Additionally, confidence intervals of the mean temperature by year will be also be plotted. This will establish a baseline for comparison with projected increases.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- subset %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(Mean_temp),\n    sd=sd(Mean_temp)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nYear\nn\nmean\nsd\nse\n\n\n\n\n1983\n31\n26.45161\n0.6587215\n0.1202655\n\n\n1993\n31\n26.20645\n0.8390214\n0.1531837\n\n\n2003\n31\n26.66129\n0.8179965\n0.1493450\n\n\n2013\n31\n27.04516\n0.9804212\n0.1789996\n\n\n2023\n31\n26.53548\n1.2755517\n0.2328828\n\n\n\n\n\n\n\nNow we are ready to create the visualization.\n\n\nCode\np1 &lt;- ggplot(my_sum) + \n            geom_errorbar_interactive(aes(x=factor(Year),\n                              ymin=mean-1.96*se, \n                              ymax=mean+1.96*se), \n                              data_id = my_sum$Year,\n                              width=0.2, \n                              colour=\"black\", \n                              alpha=0.9, \n                              size=0.5) +\n                   geom_point_interactive(aes(x=factor(Year), \n                                  y=mean, \n                                  data_id = Year,\n                                  tooltip = paste(\"Year:\", `Year`, \n                                  \"&lt;br&gt;Mean Temperature:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-1.96*se), digits = 2), \",\",\n                                  round((mean+1.96*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n             \n                   ylab(\"Mean Temperature (°C)\") + \n                  coord_cartesian(ylim = c(23.5, 29.5)) +\n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1),\n                     axis.title.x = element_blank()) +\n                   ggtitle(\"95% Confidence Interval of Mean\\n Temperature by Year\")\n\np2 &lt;- ggplot(subset,\n             aes(x = factor(Year), y = Mean_temp)) +\n  geom_boxplot_interactive(\n    aes(tooltip = paste(\"Year: \", Year,\n                        \"&lt;br&gt;Median Temperature:\", round(median(Mean_temp), digits = 2)),\n        data_id = Year),\n        fill = \"grey\") +\n  coord_cartesian(ylim = c(23.5, 29.5)) +\n    labs(title = \"Daily Mean Temperature Distribution\\n for January\", x = \"Year\") +\n  theme_minimal() +\ntheme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1),\n  axis.title.x = element_blank(),\n  axis.title.y = element_blank())\n\n\ngirafe(                                  \n  code = print(p1 + p2),                             \n  width_svg = 8,                         \n  height_svg = 8*0.618,\n  options = list(\n         opts_hover(css = \"stroke-width:1\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         ))     \n\n\n\n\n\n\n\n\n3.2 Visualizing the Future Temperature Projection\nFirst, a linear regression model will be used to analyze the trend and predict future temperatures.\n\nCodeSummary\n\n\n\n# Fit linear regression model\nmodel &lt;- lm(mean ~ Year, my_sum)\n\n\n\n\n\nCode\nsummary(model)\n\n\n\nCall:\nlm(formula = mean ~ Year, data = my_sum)\n\nResiduals:\n       1        2        3        4        5 \n 0.07290 -0.27290  0.08129  0.36452 -0.24581 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  6.420774  19.340654   0.332    0.762\nYear         0.010065   0.009656   1.042    0.374\n\nResidual standard error: 0.3053 on 3 degrees of freedom\nMultiple R-squared:  0.2659,    Adjusted R-squared:  0.02117 \nF-statistic: 1.086 on 1 and 3 DF,  p-value: 0.3739\n\n\n\n\n\nNext, we will predict the temperatures with 95% confidence interval for future 10 years, and combine the predicted data with the historical data.\n\n\nCode\n# Predict temperatures for future years\nfuture_years &lt;- c(2033, 2043, 2053, 2063, 2073, 2083, 2093, 2103, 2113, 2123)\npredicted_temperatures &lt;- predict(model, newdata = data.frame(Year = future_years),interval = \"confidence\")\n\n# Combine historical and predicted data\nhist_temperatures &lt;- cbind(my_sum$mean, my_sum$mean-1.96*my_sum$se, my_sum$mean+1.96*my_sum$se )\nall_years &lt;- c(my_sum$Year, future_years)\nall_temperatures &lt;- rbind(hist_temperatures, predicted_temperatures)\nall_data &lt;- data.frame(Year = all_years, all_temperatures)\n\nknitr::kable(all_data,row.names = FALSE, format = 'html')\n\n\n\n\n\nYear\nfit\nlwr\nupr\n\n\n\n\n1983\n26.45161\n26.21589\n26.68733\n\n\n1993\n26.20645\n25.90621\n26.50669\n\n\n2003\n26.66129\n26.36857\n26.95401\n\n\n2013\n27.04516\n26.69432\n27.39600\n\n\n2023\n26.53548\n26.07903\n26.99193\n\n\n2033\n26.88194\n25.86279\n27.90108\n\n\n2043\n26.98258\n25.67888\n28.28628\n\n\n2053\n27.08323\n25.48653\n28.67992\n\n\n2063\n27.18387\n25.28964\n29.07810\n\n\n2073\n27.28452\n25.09007\n29.47897\n\n\n2083\n27.38516\n24.88877\n29.88155\n\n\n2093\n27.48581\n24.68631\n30.28530\n\n\n2103\n27.58645\n24.48303\n30.68987\n\n\n2113\n27.68710\n24.27915\n31.09505\n\n\n2123\n27.78774\n24.07481\n31.50067\n\n\n\n\n\n\n\nNow we are ready to create the visualization.\n\n\nCode\np&lt;-ggplot(all_data, aes(x = Year, y = fit)) +\n  geom_errorbar(\n    aes(ymin=lwr, \n        ymax=upr), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point_interactive(aes(y=all_data$fit), \n           tooltip = paste(\"Year:\", all_data$Year, \n                           \"&lt;br&gt;Mean Temperature:\", round(all_data$fit, digits = 2),\n                           \"&lt;br&gt;95% CI:[\", \n                            round(all_data$lwr, digits = 2), \",\",\n                            round(all_data$upr, digits = 2),\"]\"),\n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  geom_smooth(method = \"lm\", se=FALSE) + \n  labs(title = \"Historical and Predicted Mean Temperatures\",\n       x = \"Year\",\n       y = \"Mean Temperature (°C)\") +\n  theme_minimal()\n\ngirafe(                                \n  ggobj = p,                       \n  width_svg = 8,                         \n  height_svg = 8*0.618,\n  options = list(\n         opts_hover(css = \"stroke-width:1\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         ))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nThe data presented in the above plots clearly demonstrate a consistent increase in temperature over the past five decades. The upward trend of mean temperatures for January is evident, showing a rise from 26.45°C in 1983 to 27.05°C in 2013, indicating an average annual increase of approximately 0.15°C.\nDrawing from this observed pattern, predictive models project that by 2123, the monthly mean temperature is anticipated to reach 27.79°C, with an upper boundary of 31.5°C. This suggests a projected temperature escalation of roughly 1.25°C to 4.51°C over the next decade, slightly below the previously claimed range of 1.4°C to 4.6°C."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/data/geospatial/MPSZ-2019.html",
    "href": "Take-home_Ex/Take-home_Ex04/data/geospatial/MPSZ-2019.html",
    "title": "Hui's Visual Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7",
    "section": "",
    "text": "Installing and launching the required R packages\n\npacman::p_load(sf, terra, gstat, tmap, viridis, tidyverse)\n\nImport the data\n\nrfstations &lt;- read_csv(\"data/aspatial/RainfallStation.csv\")\n\n\nrfdata &lt;- read_csv(\"data/aspatial/DAILYDATA_202402.csv\")%&gt;%\n  select(c(1,5))%&gt;%\n  group_by(Station)%&gt;%\n  summarise(MONTHSUM = sum(`Daily Rainfall Total (mm)`))%&gt;%\n  ungroup()\n\n\nrfdata &lt;- rfdata %&gt;%\n  left_join(rfstations)\n\n\nrfdata_sf&lt;- st_as_sf(rfdata,\n                     coords = c(\"Longitude\", \"Latitude\"),\n                     crs = 4326)%&gt;%\n  st_transform(crs = 3414)\n\n\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\")%&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\hci2024\\ISSS608-VAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\ntm_shape(mpsz2019)+\n  tm_borders()+\ntm_shape(rfdata_sf)+\n  tm_dots(col = 'MONTHSUM')\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "10 Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "10 Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "10 Visual Statistical Analysis",
    "section": "10.2 Visual Statistical Analysis with ggstatsplot",
    "text": "10.2 Visual Statistical Analysis with ggstatsplot\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting.\n\n\n10.2.1 Getting Started\n\na. Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nb. Importing data\n\nImportView\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nCode\nexam\n\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows\n\n\n\n\n\n\n\n\n10.2.2 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\na. Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\nb. How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n10.2.3 Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n10.2.4 Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n10.2.5 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n10.2.6 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-models",
    "title": "10 Visual Statistical Analysis",
    "section": "10.3 Visualising Models",
    "text": "10.3 Visualising Models\nIn this section, we will learn how to visualise model diagnostic and model parameters by using parameters package.\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n10.3.1 Getting Started\n\nInstalling and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nImporting Excel file: readxl methods\n\nImportView\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\n\n\n\n\n\nCode\ncar_resale\n\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that the output object car_resale is a tibble data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#references",
    "title": "10 Visual Statistical Analysis",
    "section": "10.4 References",
    "text": "10.4 References\n\nKam, T.S. (2023). Visual Statistical Analysis\nhttps://www.statisticshowto.com/bayes-factor-definition/"
  },
  {
    "objectID": "Take-home_Ex/Project_prototype/eda.html",
    "href": "Take-home_Ex/Project_prototype/eda.html",
    "title": "EDA",
    "section": "",
    "text": "1 Installing and launching the required R packages\n\npacman::p_load(tidyverse, ggiraph, ggstatsplot, patchwork, ggthemes, sf, terra, gstat, automap, tmap, viridis, zoo)\n\n\n\n2 Importing the data\n\nclimate_data &lt;- read_csv(\"data/clean_climate_data.csv\")\n\nRows: 111434 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Station\ndbl (12): Year, Month, Day, daily_rainfall, highest_30m_rainfall, highest_60...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n3 Oneway ANOVA Test\n\n#Inputs for prototyping\ninput_station &lt;- \"Changi\"\ninput_msmt &lt;- \"mean_temp\"\nstart_year &lt;- 2018\nend_year &lt;- 2020\ninput_year &lt;- seq(start_year, end_year)\n\ninput_data &lt;- climate_data %&gt;%\n  select('Station','Year','Month','Day',input_msmt)%&gt;%\n  filter(Station == input_station,\n         Year %in% input_year)\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(input_msmt)\n\n  # Now:\n  data %&gt;% select(all_of(input_msmt))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\nggbetweenstats(\n  data = input_data,\n  x = Year, \n  y = !!rlang::sym(input_msmt),\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\nWarning in min(x): no non-missing arguments to min; returning Inf\n\n\nWarning in max(x): no non-missing arguments to max; returning -Inf\n\n\n\n\n\nThe UI\n\n\n\n4 Spatial Interpolation\n\n#Importing the station data\nstations &lt;- read_csv(\"data/aspatial/RainfallStation.csv\")\n\nRows: 63 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Station\ndbl (2): Latitude, Longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#Inputs for prototyping\ninput_year &lt;- 2023\ninput_msmt &lt;- \"daily_rainfall\"\ninput_agg &lt;- \"sum\"\n\n#Preparing the input data\ninput_data &lt;- climate_data %&gt;%\n  select('Station','Year','Month','Day',input_msmt)%&gt;%\n  filter(Year == input_year)\n\nrfdata &lt;- input_data%&gt;%\n  select(c(1,5))%&gt;%\n  group_by(Station)%&gt;%\n  summarise(year_agg = switch(input_agg,\n                              sum = sum(!!rlang::sym(input_msmt)),\n                              mean = mean(!!rlang::sym(input_msmt))\n                              ))%&gt;%\n  mutate(\n    year_agg = ifelse(is.na(year_agg), 0, year_agg)\n  )%&gt;%\n  ungroup()\n\n#Converting aspatial data into geospatial data\nrfdata &lt;- rfdata %&gt;%\n  left_join(stations)\n\nJoining with `by = join_by(Station)`\n\nrfdata_sf&lt;- st_as_sf(rfdata,\n                     coords = c(\"Longitude\", \"Latitude\"),\n                     crs = 4326)%&gt;%\n  st_transform(crs = 3414)\n\n#Importing planning subzone boundary data\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\")%&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\hci2024\\ISSS608-VAA\\Take-home_Ex\\Project_prototype\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nInverse Distance Weighted\n\n#Inputs for prototyping\ninput_nmax &lt;- 3\n\n\ngrid &lt;- terra::rast(mpsz2019, \n                    nrows = 690, \n                    ncols = 1075)\n\nxy &lt;- terra::xyFromCell(grid, \n                        1:ncell(grid))\n\ncoop &lt;- st_as_sf(as.data.frame(xy), \n                 coords = c(\"x\", \"y\"),\n                 crs = st_crs(mpsz2019))\ncoop &lt;- st_filter(coop, mpsz2019)\n\nres &lt;- gstat(formula = year_agg ~ 1, \n             locations = rfdata_sf, \n             nmax = input_nmax,\n             set = list(idp = 0))\n\nresp &lt;- predict(res, coop)\n\n[inverse distance weighted interpolation]\n\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\", \n                         fun = \"mean\")\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(pred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\")\n\n\n\n\nKriging\n\nv &lt;- variogram(year_agg ~ 1, \n               data = rfdata_sf)\nplot(v)\n\n\n\n\n\n#Inputs for prototyping\ninput_model &lt;- \"Sph\"\ninput_psill &lt;- 0.5\ninput_range &lt;- 5000\ninput_nugget &lt;- 0.1\n\nfv &lt;- fit.variogram(object = v,\n                    model = vgm(\n                      psill = input_psill, \n                      model = input_model,\n                      range = input_range,  \n                      nugget = input_nugget))\n\nWarning in fit.variogram(object = v, model = vgm(psill = input_psill, model =\ninput_model, : No convergence after 200 iterations: try different initial\nvalues?\n\nk &lt;- gstat(formula = year_agg ~ 1, \n           data = rfdata_sf, \n           model = fv)\n\nresp &lt;- predict(k, coop)\n\n[using ordinary kriging]\n\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\nresp$pred &lt;- resp$pred\n\nkpred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\")\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(kpred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = \"Total yearly rainfall (mm)\") +\n  tm_layout(main.title = \"Distribution of yearly rainfall\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\nThe UI\nThe user select all required values from the first panel and click on the button. If IDW is selected, the user can change the model parameter nmax value to generate different surface map. If Kriging is selected, a empirical variogram will be shown, and the user can decide the model parameters - psill, model, range, nugget according to the variogram shown.\n\n\n\n\n5 Correlation\n\n#Inputs for prototyping\ninput1 &lt;- \"mean_temp\"\ninput2 &lt;- \"daily_rainfall\"\ninput3 &lt;- \"mean_wind\"\n\ncor_data &lt;- climate_data %&gt;%\n  select(input1, input2, input3)\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(input1)\n\n  # Now:\n  data %&gt;% select(all_of(input1))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(input2)\n\n  # Now:\n  data %&gt;% select(all_of(input2))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(input3)\n\n  # Now:\n  data %&gt;% select(all_of(input3))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\ncor_data &lt;- na.omit(cor_data)\n\nggstatsplot::ggcorrmat(\n  data = cor_data, \n  cor.vars = 1:ncol(cor_data))\n\n\n\n\nThe UI"
  },
  {
    "objectID": "Take-home_Ex/Project_prototype/data/geospatial/MPSZ-2019.html",
    "href": "Take-home_Ex/Project_prototype/data/geospatial/MPSZ-2019.html",
    "title": "Hui's Visual Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "prototype/rolling_cor.html",
    "href": "prototype/rolling_cor.html",
    "title": "tt",
    "section": "",
    "text": "pacman::p_load(tidyverse, tidyquant, corrr, cranlogs, cowplot)\n\n\n# tidyverse packages (see my laptop stickers from first post) ;)\npkgs &lt;- c(\n    \"tidyr\", \"lubridate\", \"dplyr\", \n    \"broom\", \"tidyquant\", \"ggplot2\", \"purrr\", \n    \"stringr\", \"knitr\"\n)\n# Get the downloads for the individual packages\ntidyverse_downloads &lt;- cran_downloads(\n    packages = pkgs, \n    from     = \"2017-01-01\", \n    to       = \"2017-06-30\") %&gt;%\n    tibble::as_tibble() %&gt;%\n    group_by(package)\n# Visualize the package downloads\ntidyverse_downloads %&gt;%\n    ggplot(aes(x = date, y = count, color = package)) +\n    # Data\n    geom_point(alpha = 0.5) +\n    facet_wrap(~ package, ncol = 3, scale = \"free_y\") +\n    # Aesthetics\n    labs(title = \"tidyverse packages: Daily downloads\", x = \"\",\n         subtitle = \"2017-01-01 through 2017-06-30\",\n         caption = \"Downloads data courtesy of cranlogs package\") +\n    scale_color_tq() +\n    theme_tq() +\n    theme(legend.position=\"none\")\n\n\n\n\n\n# Get data for total CRAN downloads\nall_downloads &lt;- cran_downloads(from = \"2017-01-01\", to = \"2017-06-30\") %&gt;%\n    tibble::as_tibble()\n# Visualize the downloads\nall_downloads %&gt;%\n    ggplot(aes(x = date, y = count)) +\n    # Data\n    geom_point(alpha = 0.5, color = palette_light()[[1]], size = 2) +\n    # Aesthetics\n    labs(title = \"Total CRAN Packages: Daily downloads\", x = \"\",\n         subtitle = \"2017-01-01 through 2017-06-30\",\n         caption = \"Downloads data courtesy of cranlogs package\") +\n    scale_y_continuous(labels = scales::comma) +\n    theme_tq() +\n    theme(legend.position=\"none\")\n\n\n\n\n\ntidyverse_static_correlations &lt;- tidyverse_downloads %&gt;%\n    # Data wrangling\n    spread(key = package, value = count) %&gt;%\n    left_join(all_downloads, by = \"date\") %&gt;%\n    rename(all_cran = count) %&gt;%\n    select(-date) %&gt;%\n    # Correlation and formating\n    correlate() \n\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\n# Pretty printing\ntidyverse_static_correlations %&gt;%\n    shave(upper = F)\n\n# A tibble: 10 × 11\n   term    broom  dplyr ggplot2  knitr lubridate  purrr stringr tidyquant  tidyr\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 broom      NA  0.612   0.761  0.650     0.504  0.377   0.803     0.158  0.504\n 2 dplyr      NA NA       0.718  0.700     0.573  0.566   0.695     0.123  0.629\n 3 ggplot2    NA NA      NA      0.907     0.811  0.649   0.908     0.183  0.812\n 4 knitr      NA NA      NA     NA         0.706  0.726   0.876     0.197  0.889\n 5 lubrid…    NA NA      NA     NA        NA      0.787   0.706     0.276  0.715\n 6 purrr      NA NA      NA     NA        NA     NA       0.647     0.343  0.806\n 7 stringr    NA NA      NA     NA        NA     NA      NA         0.215  0.798\n 8 tidyqu…    NA NA      NA     NA        NA     NA      NA        NA      0.252\n 9 tidyr      NA NA      NA     NA        NA     NA      NA        NA     NA    \n10 all_cr…    NA NA      NA     NA        NA     NA      NA        NA     NA    \n# ℹ 1 more variable: all_cran &lt;dbl&gt;\n\n\n\n# Network plot\ngg_all &lt;- tidyverse_static_correlations %&gt;%\n    network_plot(colours = c(palette_light()[[2]], \"white\", palette_light()[[4]])) +\n    labs(\n        title = \"Correlations of tidyverse Package Downloads to Total CRAN Downloads\",\n        subtitle = \"Looking at January through June, tidyquant is a clear outlier\"\n        ) +\n    expand_limits(x = c(-0.75, 0.25), y = c(-0.4, 0.4)) +\n    theme_tq() +\n    theme(legend.position = \"bottom\")\ngg_all\n\n\n\n\n\n# Get rolling correlations\ntidyverse_rolling_corr &lt;- tidyverse_downloads %&gt;%\n    # Data wrangling\n    left_join(all_downloads, by = \"date\") %&gt;%\n    select(date, package, count.x, count.y) %&gt;%\n    # Mutation\n    tq_mutate_xy(\n        x          = count.x,\n        y          = count.y,\n        mutate_fun = runCor, \n        # runCor args\n        n          = 30,\n        use        = \"pairwise.complete.obs\",\n        # tq_mutate args\n        col_rename = \"rolling_corr\"\n    )\n\n\n# Join static correlations with rolling correlations\ntidyverse_static_correlations &lt;- tidyverse_static_correlations %&gt;%\n    select(term, all_cran) %&gt;%\n    rename(package = term)\ntidyverse_rolling_corr &lt;- tidyverse_rolling_corr %&gt;%\n    left_join(tidyverse_static_correlations, by = \"package\") %&gt;%\n    rename(static_corr = all_cran)\n# Plot\ntidyverse_rolling_corr %&gt;%\n    ggplot(aes(x = date, color = package)) +\n    # Data\n    geom_line(aes(y = static_corr), color = \"red\") +\n    geom_point(aes(y = rolling_corr), alpha = 0.5) +\n    facet_wrap(~ package, ncol = 3, scales = \"free_y\") +\n    # Aesthetics\n    scale_color_tq() +\n    labs(\n        title = \"tidyverse: 30-Day Rolling Download Correlations, Package vs Total CRAN\",\n        subtitle = \"Relationships are dynamic vs static correlation (red line)\",\n        x = \"\", y = \"Correlation\"\n    ) +\n    theme_tq() +\n    theme(legend.position=\"none\")\n\nWarning: Removed 261 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  }
]